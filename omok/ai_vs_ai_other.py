import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import sys
import os
import time
from tqdm import tqdm

import mcts_core  # C++ ëª¨ë“ˆ

# =============================================================================
# [1] ì„¤ì •
# =============================================================================
# ëª¨ë¸ ê²½ë¡œ (ìˆ˜ì • í•„ìš”)
MODEL_A_PATH = "models/checkpoint_18000.pth"
MODEL_B_PATH = "models/checkpoint_80000.pth"

# ëŒ€ê²° ì„¤ì •
TOTAL_GAMES = 1000        # ì´ ëŒ€ê²° ìˆ˜
BATCH_SIZE = 1024           # í•œ ë²ˆì— ë™ì‹œì— ëŒë¦´ ê²Œì„ ìˆ˜ (VRAMì— ë§ì¶° ì¡°ì ˆ, 32~128 ì¶”ì²œ)
NUM_MCTS_SIMS = 800       # ë°°ì¹˜ì—ì„œëŠ” ì†ë„ë¥¼ ìœ„í•´ ì‹œë®¬ë ˆì´ì…˜ ìˆ˜ë¥¼ ì ì ˆíˆ íƒ€í˜‘
BOARD_SIZE = 15
NUM_CHANNELS = 128
NUM_RES_BLOCKS = 8
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =============================================================================
# [2] ì‹ ê²½ë§ (ê¸°ì¡´ê³¼ ë™ì¼)
# =============================================================================
class ResBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn1 = nn.GroupNorm(num_groups=8, num_channels=channels)
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn2 = nn.GroupNorm(num_groups=8, num_channels=channels)

    def forward(self, x):
        res = x
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.bn2(self.conv2(x))
        return F.relu(x + res)

class AlphaZeroNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.start_conv = nn.Conv2d(3, NUM_CHANNELS, 3, padding=1)
        self.bn_start = nn.GroupNorm(num_groups=8, num_channels=NUM_CHANNELS)
        self.backbone = nn.Sequential(*[ResBlock(NUM_CHANNELS) for _ in range(NUM_RES_BLOCKS)])
        
        self.policy_head = nn.Sequential(
            nn.Conv2d(NUM_CHANNELS, 2, 1), 
            nn.GroupNorm(num_groups=1, num_channels=2), 
            nn.ReLU(),
            nn.Flatten(), 
            nn.Linear(2 * BOARD_SIZE * BOARD_SIZE, BOARD_SIZE * BOARD_SIZE)
        )
        
        self.value_head = nn.Sequential(
            nn.Conv2d(NUM_CHANNELS, 1, 1), 
            nn.GroupNorm(num_groups=1, num_channels=1), 
            nn.ReLU(),
            nn.Flatten(), 
            nn.Linear(BOARD_SIZE * BOARD_SIZE, 64), 
            nn.ReLU(),
            nn.Linear(64, 1), 
            nn.Tanh()
        )
        
    def forward(self, x):
        x = F.relu(self.bn_start(self.start_conv(x)))
        x = self.backbone(x)
        policy = self.policy_head(x)
        value = self.value_head(x)
        return policy, value

def load_model(path):
    model = AlphaZeroNet().to(DEVICE)
    if os.path.exists(path):
        checkpoint = torch.load(path, map_location=DEVICE)
        state_dict = checkpoint['model_state_dict'] if 'model_state_dict' in checkpoint else checkpoint
        model.load_state_dict(state_dict)
        model.eval()
        return model
    else:
        print(f"âŒ ëª¨ë¸ ì—†ìŒ: {path}")
        sys.exit()

# =============================================================================
# [3] ë°°ì¹˜ ì¶”ë¡  í•¨ìˆ˜ (í•µì‹¬)
# =============================================================================
def run_batch_mcts(active_games, active_indices, models, turns, sims):
    """
    ì—¬ëŸ¬ ê²Œì„(active_games)ì˜ MCTS ì‹œë®¬ë ˆì´ì…˜ì„ í•œ ë²ˆì— ì²˜ë¦¬í•©ë‹ˆë‹¤.
    active_games: í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ê²Œì„ ë¦¬ìŠ¤íŠ¸ (MCTS ê°ì²´ë“¤ì˜ ë¦¬ìŠ¤íŠ¸)
    active_indices: ì „ì²´ ë°°ì¹˜ ì¤‘ ì§„í–‰ ì¤‘ì¸ ì¸ë±ìŠ¤
    models: {1: í‘ëª¨ë¸, -1: ë°±ëª¨ë¸}
    turns: ê° ê²Œì„ì˜ í˜„ì¬ í„´ [1, -1, 1, ...]
    """
    
    # MCTS ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜ë§Œí¼ ë°˜ë³µ
    for _ in range(sims):
        # 1. ëª¨ë“  í™œì„± ê²Œì„ì—ì„œ leaf node ìˆ˜ì§‘
        leaves = []
        valid_indices = [] # ì‹¤ì œë¡œ ê³„ì‚°ì´ í•„ìš”í•œ ê²Œì„ì˜ ì¸ë±ìŠ¤
        
        # í˜„ì¬ í„´ì¸ ëª¨ë¸ë¼ë¦¬ ë¬¶ì–´ì„œ ì²˜ë¦¬í•´ì•¼ í•¨ (í‘ì°¨ë¡€ ê²Œì„ë“¤ / ë°±ì°¨ë¡€ ê²Œì„ë“¤)
        # í•˜ì§€ë§Œ ê°„ë‹¨í•˜ê²Œ í•˜ê¸° ìœ„í•´ ì´ë²ˆì—” ê·¸ëƒ¥ ìˆœì°¨ì ìœ¼ë¡œ ìˆ˜ì§‘ í›„ Batch ì²˜ë¦¬
        
        batch_states = []
        mapping = [] # (ì›ë˜ê²Œì„ì¸ë±ìŠ¤, í„´)
        
        for i, game_idx in enumerate(active_indices):
            mcts_black, mcts_white = active_games[i]
            turn = turns[i]
            
            # í˜„ì¬ í„´ì˜ MCTS ì„ íƒ
            current_mcts = mcts_black if turn == 1 else mcts_white
            
            leaf_state = current_mcts.select_leaf()
            
            # leaf_stateê°€ Noneì´ë©´ ì´ë¯¸ ëë‚œ ê²Œì„ì´ê±°ë‚˜ ì˜¤ë¥˜ (ì—¬ê¸°ì„  skip)
            if leaf_state is not None:
                batch_states.append(leaf_state)
                mapping.append((i, turn, current_mcts))
        
        if not batch_states:
            continue

        # 2. í…ì„œ ë³€í™˜ ë° GPU ì¶”ë¡ 
        state_tensor = torch.tensor(np.array(batch_states), dtype=torch.float32).to(DEVICE)
        
        # ëª¨ë¸ì€ í‘/ë°±ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ. ë§ˆìŠ¤í¬ë¥¼ ì¨ì„œ ë”°ë¡œ ì¶”ë¡ í•˜ê±°ë‚˜, 
        # ê·¸ëƒ¥ ë‹¨ìˆœíˆ ë‚˜ëˆ ì„œ ì¶”ë¡  í›„ í•©ì¹¨. ì—¬ê¸°ì„  ë‚˜ëˆ ì„œ ì¶”ë¡ .
        
        results = [None] * len(batch_states)
        
        # (A) í‘ ì°¨ë¡€ì¸ ìƒíƒœë“¤ ì¶”ë¡ 
        black_indices = [k for k, (g_idx, t, m) in enumerate(mapping) if t == 1]
        if black_indices:
            b_states = state_tensor[black_indices]
            with torch.no_grad():
                pi, v = models[1](b_states)
            pi = F.softmax(pi, dim=1).cpu().numpy()
            v = v.cpu().numpy().flatten()
            for k, idx in enumerate(black_indices):
                results[idx] = (pi[k], v[k])
                
        # (B) ë°± ì°¨ë¡€ì¸ ìƒíƒœë“¤ ì¶”ë¡ 
        white_indices = [k for k, (g_idx, t, m) in enumerate(mapping) if t == -1]
        if white_indices:
            w_states = state_tensor[white_indices]
            with torch.no_grad():
                pi, v = models[-1](w_states)
            pi = F.softmax(pi, dim=1).cpu().numpy()
            v = v.cpu().numpy().flatten()
            for k, idx in enumerate(white_indices):
                results[idx] = (pi[k], v[k])
        
        # 3. Backpropagation
        for k, (g_idx, t, mcts_obj) in enumerate(mapping):
            prob, val = results[k]
            mcts_obj.backpropagate(prob, val)

# =============================================================================
# [4] ë°°ì¹˜ ëŒ€ê²° ì‹¤í–‰ê¸°
# =============================================================================
def run_match_batch(model_b, model_w, num_games):
    """
    model_b: í‘ëŒ ì¡ì„ ëª¨ë¸
    model_w: ë°±ëŒ ì¡ì„ ëª¨ë¸
    num_games: ì§„í–‰í•  ê²Œì„ ìˆ˜
    ë°˜í™˜: {1: í‘ìŠ¹ìˆ˜, -1: ë°±ìŠ¹ìˆ˜, 0: ë¬´ìŠ¹ë¶€}
    """
    
    results = {1: 0, -1: 0, 0: 0} # 1: í‘ìŠ¹, -1: ë°±ìŠ¹, 0: ë¬´ìŠ¹ë¶€
    remaining_games = num_games
    
    # ì§„í–‰ë°”
    pbar = tqdm(total=num_games, desc="Running Batch")
    
    while remaining_games > 0:
        # ì´ë²ˆì— ëŒë¦´ ë°°ì¹˜ í¬ê¸° ê²°ì •
        current_batch_size = min(BATCH_SIZE, remaining_games)
        
        # ê²Œì„ ì´ˆê¸°í™”
        # games list: [(mcts_black, mcts_white), ...]
        games = []
        for _ in range(current_batch_size):
            mb = mcts_core.MCTS()
            mw = mcts_core.MCTS()
            mb.reset()
            mw.reset()
            games.append((mb, mw))
            
        game_turns = [1] * current_batch_size  # ëª¨ë“  ê²Œì„ í‘ë¶€í„° ì‹œì‘
        move_counts = [0] * current_batch_size
        game_active = [True] * current_batch_size
        active_count = current_batch_size
        
        # ë°°ì¹˜ ê²Œì„ ë£¨í”„
        while active_count > 0:
            # 1. í™œì„± ê²Œì„ ì¸ë±ìŠ¤ ì¶”ì¶œ
            active_indices = [i for i, active in enumerate(game_active) if active]
            active_game_objs = [games[i] for i in active_indices]
            active_turns = [game_turns[i] for i in active_indices]
            
            # 2. ë°°ì¹˜ MCTS ìˆ˜í–‰ (ìƒê°í•˜ê¸°)
            # í‘ëª¨ë¸(model_b), ë°±ëª¨ë¸(model_w) ì „ë‹¬
            run_batch_mcts(active_game_objs, active_indices, {1: model_b, -1: model_w}, active_turns, NUM_MCTS_SIMS)
            
            # 3. ì°©ìˆ˜ ë° ê²°ê³¼ í™•ì¸
            for i in active_indices:
                mb, mw = games[i]
                turn = game_turns[i]
                current_mcts = mb if turn == 1 else mw
                
                # Temperature: ì´ˆë°˜ 6ìˆ˜ê¹Œì§€ 1.0, ì´í›„ 0.05
                temp = 1.0 if move_counts[i] < 6 else 0.05
                
                # Action ì„ íƒ
                _, pi = current_mcts.get_action_probs(temp)
                action = np.random.choice(len(pi), p=pi)
                
                # ì–‘ìª½ MCTS ì—…ë°ì´íŠ¸
                mb.update_root_game(action)
                mw.update_root_game(action)
                
                move_counts[i] += 1
                
                # ì¢…ë£Œ ì²´í¬
                is_over, winner = mb.check_game_status()
                
                if is_over:
                    results[winner] += 1
                    game_active[i] = False
                    active_count -= 1
                    pbar.update(1)
                elif move_counts[i] > 225: # ë¬´ìŠ¹ë¶€ ê°•ì œ
                    results[0] += 1
                    game_active[i] = False
                    active_count -= 1
                    pbar.update(1)
                else:
                    game_turns[i] *= -1 # í„´ êµì²´

        remaining_games -= current_batch_size
        
    pbar.close()
    return results

# =============================================================================
# [5] ë©”ì¸ ì‹¤í–‰
# =============================================================================
if __name__ == "__main__":
    print(f"ğŸ”¹ Device: {DEVICE}")
    print(f"ğŸ”¹ Model A (Evaluator): {MODEL_A_PATH}")
    print(f"ğŸ”¹ Model B (Target):    {MODEL_B_PATH}")
    print(f"ğŸ”¹ Total Games: {TOTAL_GAMES} (Half & Half)")
    print(f"ğŸ”¹ Batch Size:  {BATCH_SIZE}")
    print("-" * 50)

    model_a = load_model(MODEL_A_PATH)
    model_b = load_model(MODEL_B_PATH)

    # 1. ì „ë°˜ì „: Aê°€ í‘, Bê°€ ë°±
    print("\nâš”ï¸  [Round 1] Model A(í‘) vs Model B(ë°±) ...")
    half_games = TOTAL_GAMES // 2
    res1 = run_match_batch(model_a, model_b, half_games)
    
    # 2. í›„ë°˜ì „: Bê°€ í‘, Aê°€ ë°±
    print("\nâš”ï¸  [Round 2] Model B(í‘) vs Model A(ë°±) ...")
    res2 = run_match_batch(model_b, model_a, half_games)

    # 3. ê²°ê³¼ ì§‘ê³„ ë° ì¶œë ¥
    # res1: {1: AìŠ¹, -1: BìŠ¹, 0: ë¬´ìŠ¹ë¶€}
    # res2: {1: BìŠ¹, -1: AìŠ¹, 0: ë¬´ìŠ¹ë¶€}
    
    a_wins_black = res1[1]
    a_wins_white = res2[-1]
    b_wins_black = res2[1]
    b_wins_white = res1[-1]
    draws = res1[0] + res2[0]
    
    total_a_wins = a_wins_black + a_wins_white
    total_b_wins = b_wins_black + b_wins_white
    
    print("\n" + "="*60)
    print(f"{'FINAL STATISTICS':^60}")
    print("="*60)
    
    print(f"ğŸ“Š Model A ({MODEL_A_PATH})")
    print(f"   - í‘(Black) ìŠ¹ë¦¬: {a_wins_black} / {half_games}")
    print(f"   - ë°±(White) ìŠ¹ë¦¬: {a_wins_white} / {half_games}")
    print(f"   ğŸ‘‰ Total Wins:   {total_a_wins} ({total_a_wins/TOTAL_GAMES*100:.1f}%)")
    print("-" * 60)
    
    print(f"ğŸ“Š Model B ({MODEL_B_PATH})")
    print(f"   - í‘(Black) ìŠ¹ë¦¬: {b_wins_black} / {half_games}")
    print(f"   - ë°±(White) ìŠ¹ë¦¬: {b_wins_white} / {half_games}")
    print(f"   ğŸ‘‰ Total Wins:   {total_b_wins} ({total_b_wins/TOTAL_GAMES*100:.1f}%)")
    print("-" * 60)
    
    print(f"ğŸ¤ ë¬´ìŠ¹ë¶€(Draws): {draws} ({draws/TOTAL_GAMES*100:.1f}%)")
    print("="*60)
    
    if total_a_wins > total_b_wins:
        print("ğŸ† Winner: Model A")
    elif total_b_wins > total_a_wins:
        print("ğŸ† Winner: Model B")
    else:
        print("ğŸ¤ Result: Tie")