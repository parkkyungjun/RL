import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import sys
import os

# C++ ëª¨ë“ˆ (í•™ìŠµ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ì„í¬íŠ¸)
import mcts_core 

# =============================================================================
# [1] ì„¤ì •
# =============================================================================
BOARD_SIZE = 15
NUM_RES_BLOCKS = 8
NUM_CHANNELS = 128
MODEL_PATH = "models/checkpoint_100000.pth"
NUM_MCTS_SIMS = 1600

# =============================================================================
# [2] ì‹ ê²½ë§ í´ë˜ìŠ¤
# ============================================================================= 
class ResBlock(nn.Module):
    def __init__(self, channels):
        super().__init__()
        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn1 = nn.GroupNorm(num_groups=8, num_channels=channels)
        
        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)
        self.bn2 = nn.GroupNorm(num_groups=8, num_channels=channels)

    def forward(self, x):
        res = x
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.bn2(self.conv2(x))
        return F.relu(x + res)
    
class AlphaZeroNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.start_conv = nn.Conv2d(3, NUM_CHANNELS, 3, padding=1)
        self.bn_start = nn.GroupNorm(num_groups=8, num_channels=NUM_CHANNELS)
        
        self.backbone = nn.Sequential(*[ResBlock(NUM_CHANNELS) for _ in range(NUM_RES_BLOCKS)])
        
        self.policy_head = nn.Sequential(
            nn.Conv2d(NUM_CHANNELS, 2, 1), 
            nn.GroupNorm(num_groups=1, num_channels=2), 
            nn.ReLU(),
            nn.Flatten(), 
            nn.Linear(2 * BOARD_SIZE * BOARD_SIZE, BOARD_SIZE * BOARD_SIZE)
        )
        
        self.value_head = nn.Sequential(
            nn.Conv2d(NUM_CHANNELS, 1, 1), 
            nn.GroupNorm(num_groups=1, num_channels=1), 
            nn.ReLU(),
            nn.Flatten(), 
            nn.Linear(BOARD_SIZE * BOARD_SIZE, 64), 
            nn.ReLU(),
            nn.Linear(64, 1), 
            nn.Tanh()
        )
        
    def forward(self, x):
        x = F.relu(self.bn_start(self.start_conv(x)))
        x = self.backbone(x)
        policy = self.policy_head(x)
        value = self.value_head(x)
        return policy, value

# =============================================================================
# [3] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# =============================================================================
def print_board(board_state):
    print("\n   " + " ".join([f"{i:2}" for i in range(BOARD_SIZE)]))
    for r in range(BOARD_SIZE):
        line = f"{r:2} "
        for c in range(BOARD_SIZE):
            val = board_state[r][c]
            if val == 1:
                line += "âš« " # í‘ëŒ
            elif val == -1:
                line += "âšª " # ë°±ëŒ
            else:
                line += "â• "
        print(line)
    print()

def get_human_action():
    while True:
        try:
            inp = input("ğŸ‘‰ ë‹¹ì‹ ì˜ ì°¨ë¡€ì…ë‹ˆë‹¤ (í–‰,ì—´ ì…ë ¥ ì˜ˆ: 7,7): ")
            if ',' not in inp:
                print("í˜•ì‹ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤. 'í–‰,ì—´' í˜•íƒœë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                continue
            r, c = map(int, inp.split(','))
            
            if 0 <= r < BOARD_SIZE and 0 <= c < BOARD_SIZE:
                return r * BOARD_SIZE + c
            else:
                print(f"ë²”ìœ„ë¥¼ ë²—ì–´ë‚¬ìŠµë‹ˆë‹¤. 0~{BOARD_SIZE-1} ì‚¬ì´ë¡œ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# =============================================================================
# [4] ê²Œì„ ë£¨í”„
# =============================================================================
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"DEVICE: {device}")

    # ëª¨ë¸ ë¡œë“œ
    model = AlphaZeroNet().to(device)
    if os.path.exists(MODEL_PATH):
        try:
            checkpoint = torch.load(MODEL_PATH, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {MODEL_PATH}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
            return
    else:
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
        # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ì‹¤í–‰í•˜ì§€ ì•Šìœ¼ë ¤ë©´ return, ê·¸ëƒ¥ ì´ˆê¸°í™”ëœ ëª¨ë¸ë¡œ í•˜ë ¤ë©´ ì£¼ì„ ì²˜ë¦¬
        # return 
    model.eval()

    # MCTS ì´ˆê¸°í™”
    mcts = mcts_core.MCTS()
    mcts.reset()

    local_board = np.zeros((BOARD_SIZE, BOARD_SIZE), dtype=int)
    
    # ì„ ê³µ/í›„ê³µ ì„ íƒ
    print("="*40)
    print("      OMOK AlphaZero Human vs AI      ")
    print("="*40)
    
    while True:
        choice = input("í‘(ì„ ê³µ)ì„ í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower()
        if choice in ['y', 'n']:
            human_color = 1 if choice == 'y' else -1
            break
            
    turn = 1 # 1=í‘, -1=ë°±
    game_over = False
    color = {-1: "ë°±", 1: "í‘"}
    print_board(local_board)

    # [ìˆ˜ì •ë¨] ì²« ìˆ˜ ì¹´ìš´íŒ…ì„ ìœ„í•´ ë³€ìˆ˜ ì¶”ê°€ (ë˜ëŠ” ë³´ë“œê°€ ë¹„ì—ˆëŠ”ì§€ í™•ì¸í•´ë„ ë¨)
    move_count = 0 

    while not game_over:
        # =========================================================
        # [ìˆ˜ì •ë¨] ì²« ìˆ˜(Move 0) ê°•ì œ ì°©ìˆ˜ ë¡œì§
        # =========================================================
        if move_count == 0:
            print("âœ¨ ê³µì •í•œ ì‹œì‘ì„ ìœ„í•´ ì²« ìˆ˜ëŠ” ì²œì›(7, 7)ì— ì°©ìˆ˜í•©ë‹ˆë‹¤.")
            
            # ê°•ì œë¡œ (7, 7) ì¢Œí‘œ ê³„ì‚°
            center_r, center_c = 7, 7
            center_action = center_r * BOARD_SIZE + center_c
            
            # ì—”ì§„ ë° ë³´ë“œ ì—…ë°ì´íŠ¸
            mcts.update_root_game(center_action)
            is_game_over, winner = mcts.check_game_status() # ì—¬ê¸°ì„œ ëë‚  ì¼ì€ ì—†ê² ì§€ë§Œ í˜•ì‹ìƒ í˜¸ì¶œ
            local_board[center_r][center_c] = turn
            
            print_board(local_board)
            
            # í„´ ë„˜ê¸°ê¸°
            turn *= -1
            move_count += 1
            continue  # ë£¨í”„ì˜ ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ ë‹¤ìŒ í„´ ì§„í–‰
        
        # ---------------------------------------------------------
        # 1. Human Turn
        # ---------------------------------------------------------
        if turn == human_color:
            action = get_human_action()
            
            r, c = action // BOARD_SIZE, action % BOARD_SIZE
            if local_board[r][c] != 0:
                print("âš ï¸ ì´ë¯¸ ëŒì´ ìˆëŠ” ìë¦¬ì…ë‹ˆë‹¤! ë‹¤ì‹œ ë‘ì„¸ìš”.")
                continue
                
            mcts.update_root_game(action)
            is_game_over, winner = mcts.check_game_status()
            local_board[r][c] = turn
            print_board(local_board)
            move_count += 1 # ì°©ìˆ˜ íšŸìˆ˜ ì¦ê°€
            
            if is_game_over:
                print(f"ğŸ‰ {color[winner]}ì´ ì´ê²¼ìŠµë‹ˆë‹¤! (ë¯¿ê¸°ì§€ ì•Šë„¤ìš”)")
                break
            
        # ---------------------------------------------------------
        # 2. AI Turn
        # ---------------------------------------------------------
        else:
            print("ğŸ¤– AIê°€ ìƒê° ì¤‘ì…ë‹ˆë‹¤...", end="")
            
            for i in range(NUM_MCTS_SIMS):
                leaf_state = mcts.select_leaf()
                if leaf_state is None: 
                    continue
                
                state_tensor = torch.tensor(leaf_state, dtype=torch.float32).unsqueeze(0).to(device)
                
                with torch.no_grad():
                    pi_logits, value = model(state_tensor)
                
                probs = F.softmax(pi_logits, dim=1).cpu().numpy().flatten()
                val = value.item()
                
                mcts.backpropagate(probs, val)
                
                if i % 200 == 0: print(".", end="", flush=True)

            print(" ì™„ë£Œ!")
            
            _, pi = mcts.get_action_probs(0.0) # íƒìš•ì  ì„ íƒ
            ai_action = np.argmax(pi)
            
            r, c = ai_action // BOARD_SIZE, ai_action % BOARD_SIZE
            print(f"ğŸ¤– AIê°€ ({r}, {c})ì— ë‘ì—ˆìŠµë‹ˆë‹¤.")
            
            mcts.update_root_game(ai_action)
            is_game_over, winner = mcts.check_game_status()
            local_board[r][c] = turn
            print_board(local_board)
            move_count += 1 # ì°©ìˆ˜ íšŸìˆ˜ ì¦ê°€
            
            if is_game_over:
                print("ğŸ’€ AIê°€ ì´ê²¼ìŠµë‹ˆë‹¤. ë” ìˆ˜ë ¨í•˜ê³  ì˜¤ì„¸ìš”.")
                break

        # í„´ êµì²´
        turn *= -1

if __name__ == "__main__":
    main()